# PSPD-jogo-da-vida
Trabalho Extraclasse da disciplina PSPD, chamado Jogo da Vida,

Aluno | Matricula
--|--
Artur Vinicius Dias Nunes | 190142421
Henrique Hida | 180113569
Jo√£o Manoel Barreto Neto | 211039519 
Leonardo Milomes Vitoriano | 201000379
Miguel Matos Costa de Frias Barbosa | 211039635


[Enunciado](PSPD_LAB_JOGO_DA_VIDA.pdf)


## 1. MPI

No Jogo da Vida, o desafio computacional √© calcular, gera√ß√£o ap√≥s gera√ß√£o, o estado de cada c√©lula em um tabuleiro que pode ser muito grande. Um √∫nico processador precisa percorrer c√©lula por c√©lula, linha por linha, o que se torna extremamente lento para tabuleiros massivos.

A Vers√£o MPI tem como objetivo dividir o trabalho de simula√ß√£o da evolu√ß√£o da sociedade de organismo vivos entre os processos, o intuito √© distribuir o trabalho de modo que ele possa ser realizado mais r√°pido.

- Como compilar o c√≥digo MPI:

`mpicc -o jogodavidampi.bin jogodavidampi.c` 

- Como executar o c√≥digo MPI:

`mpirun -np 4 ./jogodavidampi `


## 2. OMP (OpenMP)


### 2.1 Jogo da Vida com OMP

O c√≥digo foi otimizado utilizando a biblioteca **OpenMP** para explorar o paralelismo de m√∫ltiplos n√∫cleos durante a simula√ß√£o do Jogo da Vida. A principal fun√ß√£o paralelizada √© `UmaVida`, que aplica as regras do aut√¥mato celular em cada c√©lula do tabuleiro. A diretiva `#pragma omp parallel for` foi utilizada sobre o loop externo que percorre as linhas do tabuleiro. Como cada linha pode ser processada de forma independente (n√£o h√° depend√™ncia entre as c√©lulas de linhas diferentes), essa paraleliza√ß√£o √© segura e eficaz. Para garantir a seguran√ßa entre threads, **as vari√°veis internas do loop (j e vizviv) foram declaradas como private**.

Com essa modifica√ß√£o, o tempo de execu√ß√£o da simula√ß√£o foi significativamente reduzido em tabuleiros grandes (por exemplo, 512x512 ou 1024x1024), aproveitando o poder computacional de CPUs com m√∫ltiplos n√∫cleos. A paraleliza√ß√£o foi implementada de forma simples, sem a necessidade de reestruturar o algoritmo original, demonstrando a efic√°cia e facilidade de uso do OpenMP para aplica√ß√µes com la√ßos paraleliz√°veis.

### 2.2 Compilar e executar

- Como compilar o c√≥digo OMP:

`gcc -o jogodavidaomp.bin jogodavidaomp.c -fopenmp` 

- Como executar o c√≥digo OMP:

`./jogodavidaomp.bin` 


### 2.3 Resultado

O resultado da execu√ß√£o pode ser visualizado na imagem abaixo:

![omp](assets/omp.png)


## 3. Jogo da Vida - CUDA
### Descri√ß√£o da Implementa√ß√£o

Nesta etapa do projeto, foi desenvolvida a vers√£o CUDA do Jogo da Vida, denominada `jogodavida.cu`, com o objetivo de executar a evolu√ß√£o da sociedade de organismos vivos utilizando uma GPU do cluster.

#### Estrutura de Paraleliza√ß√£o
- Cada thread CUDA foi respons√°vel por calcular a evolu√ß√£o de uma c√©lula individual.
- O c√°lculo da nova gera√ß√£o foi implementado em um kernel CUDA chamado `UmaVidaKernel`.
- A execu√ß√£o paralela foi organizada com blocos de 16x16 threads e grids dimensionados para cobrir todo o tabuleiro.

#### Troca de Dados
- Foi realizada a aloca√ß√£o de mem√≥ria na GPU com `cudaMalloc`.
- As matrizes do tabuleiro foram transferidas da CPU para a GPU usando `cudaMemcpy`.
- As trocas entre as matrizes de entrada e sa√≠da foram realizadas diretamente na GPU, com sincroniza√ß√£o entre as chamadas do kernel.

#### Dificuldades e Solu√ß√µes
- **Desafio:** Gerenciar os √≠ndices e a borda do tabuleiro na GPU.
- **Solu√ß√£o:** Foi criada uma fun√ß√£o auxiliar `device_ind2d` para o c√°lculo correto dos √≠ndices no c√≥digo CUDA.
- **Desafio:** Sincronizar corretamente as gera√ß√µes.
- **Solu√ß√£o:** Utiliza√ß√£o de `cudaDeviceSynchronize` ap√≥s cada chamada do kernel para garantir que as threads terminaram antes da pr√≥xima itera√ß√£o.

#### C√≥digo CUDA Desenvolvido
O c√≥digo desenvolvido est√° dispon√≠vel no arquivo `jogodavida.cu` e segue a l√≥gica fornecida no c√≥digo base sequencial, adaptando a fun√ß√£o `UmaVida` para um kernel CUDA com paraleliza√ß√£o eficiente.

### Descri√ß√£o do Experimento

#### Configura√ß√£o de Teste
- **Host:** 164.41.20.252 
- **Dimens√µes dos tabuleiros:** Testes realizados para tamanhos 2^3, 2^4, ..., 2^10

#### Procedimento
1. O tempo de execu√ß√£o foi medido para cada tamanho de tabuleiro, utilizando a fun√ß√£o `wall_time`.
2. Foram executadas todas as itera√ß√µes de acordo com o c√≥digo base, at√© que o "veleiro" alcan√ßasse o canto inferior direito.
3. As execu√ß√µes foram feitas no cluster, garantindo compatibilidade com o ambiente de avalia√ß√£o.

#### Resultados (Exemplo)
| Tamanho (N) | Tempo Total (s) |
|-------------|-----------------|
| 8           | 0.1579599       |
| 16          | 0.0005600       |
| 32          | 0.0010312       |
| 64          | 0.0020881       |
| 128         | 0.0045030       |
| 256         | 0.0113790       |
| 512         | 0.0453660       |
| 1024        | 0.3059671       |


### Conclus√£o

A implementa√ß√£o CUDA apresentou execu√ß√£o correta, com o "veleiro" alcan√ßando a posi√ß√£o esperada no tabuleiro em todas as execu√ß√µes. O paralelismo oferecido pela GPU trouxe uma melhora significativa no tempo de execu√ß√£o comparado √†s vers√µes sequenciais.

Resultados preliminares mostram que quanto maior o tamanho do tabuleiro, maior o benef√≠cio da paraleliza√ß√£o com CUDA, evidenciando o potencial das GPUs para esse tipo de problema.

Al√©m disso, o c√≥digo foi desenvolvido com foco na portabilidade e compatibilidade com o cluster, utilizando pr√°ticas corretas de aloca√ß√£o, c√≥pia de dados e sincroniza√ß√£o.

### Instru√ß√µes de Compila√ß√£o e Execu√ß√£o

#### Compila√ß√£o:
```bash
nvcc -o jogodavida jogodavida.cu
```

#### Execu√ß√£o:
```bash
./jogodavida
```

### Coment√°rios 
- O c√≥digo foi validado para diferentes tamanhos de tabuleiro.
- A paraleliza√ß√£o foi eficiente e a sincroniza√ß√£o adequada.
- O c√≥digo pode ser facilmente ajustado para diferentes configura√ß√µes de GPU e dimens√µes de bloco.

## 4. Jogo da Vida ‚Äì CUDA + OpenMP

### Descri√ß√£o da Implementa√ß√£o

Nesta etapa do projeto, foi desenvolvida uma vers√£o h√≠brida do Jogo da Vida, implementada no arquivo `jogodavidaompgpu.cu`. O objetivo principal foi explorar o paralelismo **em duas camadas**:

- **CUDA**: para acelerar a evolu√ß√£o do tabuleiro em uma GPU.
- **OpenMP**: para paralelizar os testes com m√∫ltiplos tamanhos de tabuleiro em uma CPU multicore.

Esta combina√ß√£o foi executada no cluster, aproveitando ao m√°ximo os recursos computacionais dispon√≠veis.

---

### Estrutura de Paraleliza√ß√£o

#### üîπ CUDA (GPU)
- Cada **thread CUDA** √© respons√°vel por calcular a evolu√ß√£o de uma **√∫nica c√©lula** do tabuleiro.
- O c√°lculo da nova gera√ß√£o foi implementado no kernel `UmaVidaKernel`.
- A organiza√ß√£o da execu√ß√£o paralela utiliza blocos de **16x16 threads**, formando grids suficientes para cobrir toda a matriz de c√©lulas.

#### üî∏ OpenMP (CPU)
- Utilizado para executar v√°rios **experimentos simultaneamente**, variando o tamanho do tabuleiro (de 2¬≥ at√© 2¬π‚Å∞).
- As se√ß√µes cr√≠ticas e redu√ß√µes foram tratadas com diretivas como `#pragma omp parallel for` e `reduction`.

---

### Troca de Dados

- A mem√≥ria da GPU foi alocada com `cudaMalloc`.
- Os tabuleiros foram copiados da CPU para a GPU usando `cudaMemcpy`.
- A altern√¢ncia entre as matrizes de entrada e sa√≠da foi feita **dentro da GPU**, sem transfer√™ncias intermedi√°rias para a CPU.
- A sincroniza√ß√£o entre as gera√ß√µes foi garantida com `cudaDeviceSynchronize` ap√≥s cada chamada ao kernel.

---

### Dificuldades e Solu√ß√µes

| Desafio | Solu√ß√£o |
|--------|---------|
| Gerenciamento dos √≠ndices e da borda do tabuleiro na GPU | Implementa√ß√£o da fun√ß√£o auxiliar `device_ind2d` para c√°lculo correto dos √≠ndices 2D. |
| Sincroniza√ß√£o correta entre as gera√ß√µes | Uso de `cudaDeviceSynchronize()` ap√≥s cada kernel para garantir conclus√£o antes da pr√≥xima etapa. |
| Balanceamento entre OpenMP e CUDA | Cada thread OpenMP opera de forma independente em seu pr√≥prio experimento CUDA. |

---

### C√≥digo CUDA Desenvolvido

O c√≥digo est√° dispon√≠vel no arquivo `jogodavidaompgpu.cu`. Ele segue a l√≥gica do c√≥digo sequencial base, adaptando a fun√ß√£o `UmaVida` para um kernel CUDA (`UmaVidaKernel`). A evolu√ß√£o do jogo ocorre dentro da GPU, e cada simula√ß√£o de tamanho diferente √© executada de forma paralela na CPU.

---

### Descri√ß√£o do Experimento

#### üß™ Configura√ß√£o de Teste
- **Host:** 164.41.20.252  
- **Ambiente:** cluster 
- **Tamanhos testados:** 2¬≥, 2‚Å¥, ..., 2¬π‚Å∞

#### üìã Procedimento
- Para cada tamanho de tabuleiro, foi executada a simula√ß√£o at√© que o padr√£o inicial (*glider*) atingisse o canto inferior direito.
- Os tempos de execu√ß√£o foram coletados com a fun√ß√£o `wall_time`.
- Cada simula√ß√£o foi executada em paralelo com OpenMP, e processada na GPU com CUDA.

---

### üßæ Resultados (Exemplo)

| Tamanho (N) | Tempo Total (s) |
|-------------|-----------------|
| 8           | 0.0001990       |
| 16          | 0.0002240       |
| 32          | 0.0005210       |
| 64          | 0.0014350       |
| 128         | 0.0041300       |
| 256         | 0.0132200       |
| 512         | 0.0467100       |
| 1024        | 0.3152190       |

---

### üß† Conclus√£o

A implementa√ß√£o h√≠brida **CUDA + OpenMP** apresentou resultados corretos em todos os testes, com o padr√£o *glider* alcan√ßando a posi√ß√£o esperada no tabuleiro final.  

- O uso de **CUDA** foi fundamental para acelerar o c√°lculo das gera√ß√µes do Jogo da Vida.
- O uso de **OpenMP** aumentou a efici√™ncia ao permitir m√∫ltiplas simula√ß√µes paralelas, explorando a CPU.
- A **sincroniza√ß√£o e gerenciamento de mem√≥ria** foram bem-sucedidos, garantindo a confiabilidade da execu√ß√£o.
- Observa-se que **o ganho de desempenho cresce com o aumento do tamanho do tabuleiro**, o que evidencia o poder do paralelismo em aplica√ß√µes de simula√ß√£o.

---

### Instru√ß√µes de Compila√ß√£o e Execu√ß√£o

#### Compila√ß√£o

Utilize o compilador `nvcc`, com suporte ao OpenMP:

```bash
nvcc -Xcompiler -fopenmp -o jogodavidaompgpu jogodavidaompgpu.cu


